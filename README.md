# End-to-End-ML-pipeline-using-DVC-Aws

An end-to-end **Machine Learning pipeline** for **Spam SMS Classification** built with **DVC (Data Version Control)**, **Git**, and **AWS S3** for scalable and reproducible workflows.  

The project demonstrates how to go from raw data â preprocessing â feature engineering â model training â evaluation while ensuring **automation, version control, and cloud storage** of artifacts.  

---

## ğŸ“– Table of Contents  
- [Overview](#-overview)  
- [Features](#-features)  
- [Tech Stack](#-tech-stack)  
- [Project Structure](#-project-structure)  
- [Workflow](#-workflow)  
- [Installation & Setup](#-installation--setup)  
- [Usage](#-usage)  
- [Results](#-results)  
- [Future Improvements](#-future-improvements)  
- [Acknowledgements](#-acknowledgements)  

---

## ğŸ” Overview  
The task is to classify SMS messages as **Spam** or **Ham (Not Spam)** using **Natural Language Processing (NLP)** techniques.  

Key aspects of this project:  
- Modularized ML workflow split into reusable Python scripts.  
- Data & model versioning handled by **DVC**.  
- Storage of large files and artifacts in **AWS S3**.  
- Reproducible and automated experiments with `dvc repro`.  

---

## âœ¨ Features  
âœ”ï¸ Data exploration and baseline experiments in Jupyter Notebook  
âœ”ï¸ Modular pipeline with distinct stages (ingestion â†’ preprocessing â†’ feature engineering â†’ model training â†’ evaluation)  
âœ”ï¸ NLP processing: text cleaning, **Porter Stemming**, **TF-IDF vectorization**  
âœ”ï¸ Automated pipeline execution using **DVC**  
âœ”ï¸ Remote storage of data/models in **AWS S3**  
âœ”ï¸ Easy reproducibility and collaboration  

---

## âš™ï¸ Tech Stack  
- **Programming Language**: Python 3  
- **Tools & Platforms**: DVC, Git, AWS S3, Jupyter Notebook  
- **Libraries**:  
  - Data Handling â†’ Pandas, NumPy  
  - NLP â†’ NLTK (Porter Stemmer), Scikit-learn (TfidfVectorizer)  
  - Modeling â†’ Scikit-learn (Logistic Regression, Naive Bayes, etc.)  
  - Evaluation â†’ Accuracy, Precision, Recall, F1-Score  

---

## ğŸ“‚ Project Structure  

```bash
End-to-End-ML-pipeline-using-DVC-Aws/
â”‚
â”œâ”€â”€ .dvc/                         # DVC internal files
â”œâ”€â”€ .dvclive/                      
â”œâ”€â”€ experiments/                  # Experimental work
â”‚   â”œâ”€â”€ mynotebook.ipynb          # EDA and prototyping
â”‚   â””â”€â”€ spam.csv                  # Original dataset
â”‚
â”œâ”€â”€ src/                          # Modular pipeline source code
â”‚   â”œâ”€â”€ data_ingestion.py         # Load and validate data
â”‚   â”œâ”€â”€ data_preprocessing.py     # Text cleaning & stemming
â”‚   â”œâ”€â”€ feature_Engineering.py    # TF-IDF vectorization
â”‚   â”œâ”€â”€ model_building.py         # Model training
â”‚   â””â”€â”€ model_evaluation.py       # Performance metrics
â”‚
â”œâ”€â”€ params.yaml                   # Configuration parameters
â”œâ”€â”€ dvc.yaml                      # Pipeline definition
â”œâ”€â”€ dvc.lock                      
â”œâ”€â”€ .gitignore                    # Git ignore rules
â””â”€â”€ README.md                     # Project documentation
â”œâ”€â”€ .dvcignore
â”œâ”€â”€ .gitignore                    

```

## ğŸ”„ Workflow  

1. **Data Exploration**  
   - Perform EDA & baseline experiments in `experiments/mynotebook.ipynb`.  

2. **Pipeline Stages** (src folder)  
   - `data_ingestion.py` â†’ Load raw dataset.  
   - `data_preprocessing.py` â†’ Clean text (lowercasing, punctuation removal, etc.).  
   - `feature_engineering.py` â†’ Apply stemming & TF-IDF vectorization.  
   - `model_building.py` â†’ Train spam classifier models.  
   - `model_evaluation.py` â†’ Evaluate with metrics like accuracy, F1-score.  

3. **Version Control with DVC**  
   - Data & model files tracked using **DVC**.  
   - Pipeline defined in `dvc.yaml`.  

4. **Cloud Storage with AWS S3**  
   - Configured S3 bucket for storing large data/artifacts.  
   - Artifacts pushed with `dvc push`.  

5. **Reproducibility**  
   - Any contributor can run:  
     ```bash
     dvc repro
     ```
     to reproduce the entire pipeline.  

---

